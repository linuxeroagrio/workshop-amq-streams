== Production-ready topologies: sizing and persistence

In the previous module, we have set up a simple Apache Kafka cluster.
It is suitable for development and experimentation, but not for a production setting.
In this module you will learn how to use AMQ Streams for configuring a Kafka cluster for production usage, in particular sizing and persistence settings.

=== Some words on size and persistence

Configuring your Kafka cluster depends on a number of factors, and in particular of your development and production requirements for throughput and scalability, but there are a few principles to observe:

* Making sure that you deploy at least 3 Kafka brokers for scaling and HA
* Making sure that topics are replicated on at least two nodes
* Making sure that your Zookeeper ensemble has at least 3 nodes
* Making sure that the data of your Kafka cluster is persistent

Our ephemeral cluster created in the previous module meets some but not all of these criteria: it has the minimum number of nodes for both Kafka and Zookeeper, but it is not persistent.
Plus, we really had no control over sizing - we just used a default!

=== Configuring the size of your Kafka cluster deployments

AMQ Streams treats an Apache Kafka cluster deployment as a custom resource and controls the configuration of an Apache Kafka cluster through a Custom Resource Definition (CRD).
Let's take a quick look at the resource descriptor for the cluster we just deployed:

----
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: simple-cluster
  namespace: amq-streams
spec:
  kafka:
    replicas: 1
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 1
    storage:
      type: ephemeral
  zookeeper:
    replicas: 1
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

----

Let's take a look at a few of the cluster properties.
The cluster has:

* a name: `metadata.name: simple-cluster`
* a number of kafka replicas: `spec.kafka.replicas: 1`
* storage configuration for the Kafka cluster: `spec.kafka.storage: ephemeral`
* configurations for listeners and configuration parameters for the brokers (e.g. replication settings)
* a number of zookeeper replicas: `spec.zookeeper.replicas: 1`
* storage configuration for the ZooKeeper cluster: `spec.zookeeper.storage: ephemeral`

=== Configuring a cluster of a given size and persistence

While a single-broker ephemeral cluster is good enough for development and experimentation, it is definitely not a good option for production and staging workloads.
A healthy cluster must have more than one broker for HA and throughput, and must persist its data on a persistent filesystem.

First let's check if the previously deployed cluster is still there.

----
oc get -n amq-streams kafka
----

You might get an empty result, but in case you don't, just remove the existing cluster.

----
oc delete -n amq-streams kafka simple-cluster
----

Now let's create and deploy a new kafka cluster resource.
The definition of the cluster is below:

----
cat << EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-ready
  namespace: amq-streams
spec:
  kafka:
    replicas: 3
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----

The cluster `production-ready` has the minimal settings for a highly available, persistent cluster.

* 3 Kafka broker nodes - this is the minimum recommended number for a production deployment
* 3 ZooKeeper nodes - this is the minimum recommended number for a production deployments
* `persistent-claim` storage that ensures that persistent volumes are allocated to Kafka and ZooKeeper instances

Note that while the minimum number is 3 for both, the number of Kafka brokers is likely to be different from the number of ZooKeeper nodes.
The latter may be less than the number of Kafka brokers.
Other settings control the replication factors for offsets and transaction logs.
A minimum of two is recommended.

Notice the number of pods and the corresponding persistent claims in the project

----
oc get pods,pvc -n amq-streams

NAME                                                    READY   STATUS    RESTARTS   AGE
pod/production-ready-entity-operator-5666dd8689-q4qgg   3/3     Running   0          12m
pod/production-ready-kafka-0                            1/1     Running   0          12m
pod/production-ready-kafka-1                            1/1     Running   0          12m
pod/production-ready-kafka-2                            1/1     Running   0          12m
pod/production-ready-zookeeper-0                        1/1     Running   0          13m
pod/production-ready-zookeeper-1                        1/1     Running   0          13m
pod/production-ready-zookeeper-2                        1/1     Running   0          13m
pod/strimzi-cluster-operator-676c86db94-445lm           1/1     Running   0          70m

NAME                                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                           AGE
persistentvolumeclaim/data-production-ready-kafka-0       Bound    pvc-77671a8c-fca1-4063-b633-3e5d83e4ffb3   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   12m
persistentvolumeclaim/data-production-ready-kafka-1       Bound    pvc-7d6bf818-adfb-4962-8713-30a5565138bd   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   12m
persistentvolumeclaim/data-production-ready-kafka-2       Bound    pvc-b6a5e6a4-f6f9-403c-8c98-0b713b7bc06d   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   12m
persistentvolumeclaim/data-production-ready-zookeeper-0   Bound    pvc-9bcfbd19-1fff-4889-91fe-609cd36ff61f   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   13m
persistentvolumeclaim/data-production-ready-zookeeper-1   Bound    pvc-5fa51ce0-0d0f-474f-acdc-1a11cf3eec65   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   13m
persistentvolumeclaim/data-production-ready-zookeeper-2   Bound    pvc-021c9687-1c81-4080-bbaa-bb7219d51433   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   13m
----

==== Scaling up the cluster

Let us scale up the cluster.
A corresponding resource would look like below (note that the only property that changes is `spec.kafka.replicas).

----
cat << EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-ready
  namespace: amq-streams
spec:
  kafka:
    replicas: 5
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----

Notice the number of pods of the Kafka cluster increasing to 5 and the corresponding persistent claims.

----
oc get pods,pvc -n amq-streams

NAME                                                    READY   STATUS    RESTARTS   AGE
pod/production-ready-entity-operator-5666dd8689-q4qgg   3/3     Running   0          15m
pod/production-ready-kafka-0                            1/1     Running   0          15m
pod/production-ready-kafka-1                            1/1     Running   0          15m
pod/production-ready-kafka-2                            1/1     Running   0          15m
pod/production-ready-kafka-3                            1/1     Running   0          68s
pod/production-ready-kafka-4                            1/1     Running   0          68s
pod/production-ready-zookeeper-0                        1/1     Running   0          17m
pod/production-ready-zookeeper-1                        1/1     Running   0          17m
pod/production-ready-zookeeper-2                        1/1     Running   0          17m
pod/strimzi-cluster-operator-676c86db94-445lm           1/1     Running   0          73m

NAME                                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                           AGE
persistentvolumeclaim/data-production-ready-kafka-0       Bound    pvc-77671a8c-fca1-4063-b633-3e5d83e4ffb3   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   15m
persistentvolumeclaim/data-production-ready-kafka-1       Bound    pvc-7d6bf818-adfb-4962-8713-30a5565138bd   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   15m
persistentvolumeclaim/data-production-ready-kafka-2       Bound    pvc-b6a5e6a4-f6f9-403c-8c98-0b713b7bc06d   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   15m
persistentvolumeclaim/data-production-ready-kafka-3       Bound    pvc-2a1fef21-7673-4e3d-a3c3-8ab8f44008f9   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   68s
persistentvolumeclaim/data-production-ready-kafka-4       Bound    pvc-544dd558-a06a-470b-bd4e-24a0a5b6678f   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   68s
persistentvolumeclaim/data-production-ready-zookeeper-0   Bound    pvc-9bcfbd19-1fff-4889-91fe-609cd36ff61f   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
persistentvolumeclaim/data-production-ready-zookeeper-1   Bound    pvc-5fa51ce0-0d0f-474f-acdc-1a11cf3eec65   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
persistentvolumeclaim/data-production-ready-zookeeper-2   Bound    pvc-021c9687-1c81-4080-bbaa-bb7219d51433   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
----

Now let's scale down the cluster again.

----
cat << EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-ready
  namespace: amq-streams
spec:
  kafka:
    replicas: 3
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----

Notice the number of pods of the Kafka cluster decreasing back to 3.
The persistent claims for nodes 3 and 4 are still active.

----
oc get pods,pvc -n amq-streams

NAME                                                    READY   STATUS    RESTARTS   AGE
pod/production-ready-entity-operator-5666dd8689-q4qgg   3/3     Running   0          16m
pod/production-ready-kafka-0                            1/1     Running   0          17m
pod/production-ready-kafka-1                            1/1     Running   0          17m
pod/production-ready-kafka-2                            1/1     Running   0          17m
pod/production-ready-zookeeper-0                        1/1     Running   0          18m
pod/production-ready-zookeeper-1                        1/1     Running   0          18m
pod/production-ready-zookeeper-2                        1/1     Running   0          18m
pod/strimzi-cluster-operator-676c86db94-445lm           1/1     Running   0          75m

NAME                                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                           AGE
persistentvolumeclaim/data-production-ready-kafka-0       Bound    pvc-77671a8c-fca1-4063-b633-3e5d83e4ffb3   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
persistentvolumeclaim/data-production-ready-kafka-1       Bound    pvc-7d6bf818-adfb-4962-8713-30a5565138bd   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
persistentvolumeclaim/data-production-ready-kafka-2       Bound    pvc-b6a5e6a4-f6f9-403c-8c98-0b713b7bc06d   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   17m
persistentvolumeclaim/data-production-ready-kafka-3       Bound    pvc-2a1fef21-7673-4e3d-a3c3-8ab8f44008f9   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   2m41s
persistentvolumeclaim/data-production-ready-kafka-4       Bound    pvc-544dd558-a06a-470b-bd4e-24a0a5b6678f   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   2m41s
persistentvolumeclaim/data-production-ready-zookeeper-0   Bound    pvc-9bcfbd19-1fff-4889-91fe-609cd36ff61f   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   18m
persistentvolumeclaim/data-production-ready-zookeeper-1   Bound    pvc-5fa51ce0-0d0f-474f-acdc-1a11cf3eec65   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   18m
persistentvolumeclaim/data-production-ready-zookeeper-2   Bound    pvc-021c9687-1c81-4080-bbaa-bb7219d51433   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   18m
----

What does this mean?
Let's scale up the cluster again.

----
cat << EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-ready
  namespace: amq-streams
spec:
  kafka:
    replicas: 5
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----

Notice the number of pods increasing back to 5 and the corresponding persistent volume claims being reallocated to the existing nodes.
This means that the newly started instances will resume from where the previous instances 3 and 4 left off.

----
oc get pods,pvc -n amq-streams

NAME                                                    READY   STATUS    RESTARTS   AGE
pod/production-ready-entity-operator-5666dd8689-q4qgg   3/3     Running   0          18m
pod/production-ready-kafka-0                            1/1     Running   0          19m
pod/production-ready-kafka-1                            1/1     Running   0          19m
pod/production-ready-kafka-2                            1/1     Running   0          19m
pod/production-ready-kafka-3                            1/1     Running   0          40s
pod/production-ready-kafka-4                            1/1     Running   0          40s
pod/production-ready-zookeeper-0                        1/1     Running   0          20m
pod/production-ready-zookeeper-1                        1/1     Running   0          20m
pod/production-ready-zookeeper-2                        1/1     Running   0          20m
pod/strimzi-cluster-operator-676c86db94-445lm           1/1     Running   0          77m

NAME                                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                           AGE
persistentvolumeclaim/data-production-ready-kafka-0       Bound    pvc-77671a8c-fca1-4063-b633-3e5d83e4ffb3   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   19m
persistentvolumeclaim/data-production-ready-kafka-1       Bound    pvc-7d6bf818-adfb-4962-8713-30a5565138bd   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   19m
persistentvolumeclaim/data-production-ready-kafka-2       Bound    pvc-b6a5e6a4-f6f9-403c-8c98-0b713b7bc06d   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   19m
persistentvolumeclaim/data-production-ready-kafka-3       Bound    pvc-2a1fef21-7673-4e3d-a3c3-8ab8f44008f9   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   4m33s
persistentvolumeclaim/data-production-ready-kafka-4       Bound    pvc-544dd558-a06a-470b-bd4e-24a0a5b6678f   3Gi        RWO            ocs-external-storagecluster-ceph-rbd   4m33s
persistentvolumeclaim/data-production-ready-zookeeper-0   Bound    pvc-9bcfbd19-1fff-4889-91fe-609cd36ff61f   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   20m
persistentvolumeclaim/data-production-ready-zookeeper-1   Bound    pvc-5fa51ce0-0d0f-474f-acdc-1a11cf3eec65   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   20m
persistentvolumeclaim/data-production-ready-zookeeper-2   Bound    pvc-021c9687-1c81-4080-bbaa-bb7219d51433   1Gi        RWO            ocs-external-storagecluster-ceph-rbd   20m
----

Three broker nodes will be sufficient for our lab, so we can scale things down again:

----
cat << EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-ready
  namespace: amq-streams
spec:
  kafka:
    replicas: 3
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----
